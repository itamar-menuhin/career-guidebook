---
kind: focus_area
id: ai-safety
title: AI Safety
summary: "Mitigate catastrophic risks from advanced AI systems by working on technical alignment, governance, or strategy."
role_shapes:
- "**Technical Research:** Theory, Interpretability, Model Evals. (Focus: *Understanding* systems)."
- "**Safety Engineering:** Secure Infrastructure, Reliability, Red Teaming. (Focus: *Building* robust systems)."
- "**Governance & Strategy:** Policy analysis, Compute Governance, International Coordination. (Focus: *Governing* deployment)."
fit_signals:
- "Motivated by catastrophic risk (high-stakes failure modes)"
- "Strong technical / conceptual / strategic skills"
- "Comfortable with significant uncertainty and high abstraction"
common_confusions: []
---

Mitigate catastrophic risks from advanced AI systems by working on technical alignment, governance, or strategy.
